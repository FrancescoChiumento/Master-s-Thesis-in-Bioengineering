{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> UNet testing saving .png files\n",
    "\n",
    "**Content under Creative Commons Attribution license CC-BY-NC-SA 4.0**  \n",
    "**Code under GNU-GPL v3 License**  \n",
    "**Â© 2023 Francesco Chiumento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Through this notebook, it is possible to utilize a previously saved checkpoint of the UNet neural network to segment femoral cartilages in 2D images extracted from MRI scans of a set of patients. In this version of the code, it is possible to provide the ground truth of the respective binary masks of the patients to visualize the qualitative results of the DICE indices of the obtained 2D segmentations;\n",
    "\n",
    "- The ultimate goal is to obtain reconstructed segmentations in three-dimensional volumes from the 2D segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import and Module Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slice_extraction import process_directory, clean_folder\n",
    "from unet_segmentation import run_segmentation\n",
    "from compositionMha import combine_slices_to_mha\n",
    "from ipywidgets import Checkbox, VBox\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toggle DICE Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When value is set to True, the option to utilize the binary ground truth masks for qualitative evaluation (using the Dice index) of the neural network's performance is available;\n",
    "\n",
    "- In the absence of ground truth masks, set value to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_masks_checkbox = Checkbox(\n",
    "    value=True,\n",
    "    description='Use Masks for DICE Calculation',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(VBox([use_masks_checkbox]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path and Settings Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In *images_dir* and *masks_dir* (if masks are available), place the images and their corresponding binary masks from which to extract individual slices for segmentation;\n",
    "- In *images_slices* and *masks_slices*, individual slices extracted from the images and their corresponding masks (if available) will be saved;\n",
    "- checkpoint_path represents the saved checkpoint obtained from training and validating the neural network;\n",
    "- *predictions* is the folder where the 2D segmentations of individual slices will be saved;\n",
    "- *segmentations* is the folder where the reconstructed 3D segmentations obtained from the *predictions* folder will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and settings\n",
    "\n",
    "images_dir = r\"your/path/here\"\n",
    "masks_dir = r\"your/path/here\"\n",
    "images_slices = r\"your/path/here\"\n",
    "masks_slices = r\"your/path/here\"\n",
    "checkpoint_path = r\"your/path/here\"\n",
    "predictions = r\"your/path/here\"\n",
    "segmentations = r\"your/path/here\"\n",
    "\n",
    "spacing = (0.4121, 0.4121, 0.4)  # Update according to your image spacing\n",
    "\n",
    "should_flip = True # Option to flip the images if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Directory Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dirs = os.listdir(images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Data Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patient_dirs:\n",
    "    image_mha_path = os.path.join(images_dir, patient)\n",
    "    mask_mha_path = os.path.join(masks_dir, patient)\n",
    "    \n",
    "    # Clean the folders for slices and predictions before each patient\n",
    "    clean_folder(images_slices)\n",
    "    clean_folder(masks_slices)\n",
    "    clean_folder(predictions)\n",
    "\n",
    "    # Call the updated function with the specific file paths\n",
    "    process_directory(image_mha_path, mask_mha_path, images_slices, masks_slices, use_masks=use_masks_checkbox.value)\n",
    "\n",
    "    run_segmentation(checkpoint_path, images_slices, masks_slices, predictions, device, use_masks=use_masks_checkbox.value)\n",
    "\n",
    "    combine_slices_to_mha(predictions, os.path.join(segmentations, f\"{patient}_segmentation.mha\"), spacing, should_flip)\n",
    "   \n",
    "    print(f\"The process has been completed for the patient {patient}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer system details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
