{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> UNet testing saving .png files\n",
    "\n",
    "**Content under Creative Commons Attribution license CC-BY-NC-SA 4.0**  \n",
    "**Code under GNU-GPL v3 License**  \n",
    "**Â© 2023 Francesco Chiumento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Through this notebook, it is possible to utilize a previously saved checkpoint of the UNet neural network to segment femoral cartilages in 2D images extracted from MRI scans of a set of patients. In this version of the code, it is possible to provide the ground truth of the respective binary masks of the patients to visualize the qualitative results of the DICE indices of the obtained 2D segmentations.\n",
    "\n",
    "- The ultimate goal is to obtain reconstructed segmentations in three-dimensional volumes from the 2D segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import and Module Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slice_extraction import process_directory, clean_folder\n",
    "from unet_segmentation import run_segmentation\n",
    "from compositionMha import combine_slices_to_mha\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path and Settings Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and settings\n",
    "\n",
    "images_dir = r\"your/path/here\"\n",
    "masks_dir = r\"your/path/here\"\n",
    "images_slices = r\"your/path/here\"\n",
    "masks_slices = r\"your/path/here\"\n",
    "checkpoint_path = r\"your/path/here\"\n",
    "predictions = r\"your/path/here\"\n",
    "segmentations = r\"your/path/here\"\n",
    "\n",
    "spacing = (0.4121, 0.4121, 0.4)  # Update according to your image spacing\n",
    "\n",
    "should_flip = True # Option to flip the images if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Directory Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dirs = os.listdir(images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Data Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patient_dirs:\n",
    "    image_mha_path = os.path.join(images_dir, patient)\n",
    "    mask_mha_path = os.path.join(masks_dir, patient)\n",
    "    \n",
    "    # Clean the folders for slices and predictions before each patient\n",
    "    clean_folder(images_slices)\n",
    "    clean_folder(masks_slices)\n",
    "    clean_folder(predictions)\n",
    "\n",
    "    # Call the updated function with the specific file paths\n",
    "    process_directory(image_mha_path, mask_mha_path, images_slices, masks_slices)\n",
    "\n",
    "    run_segmentation(checkpoint_path, images_slices, masks_slices, predictions, device)\n",
    "\n",
    "    combine_slices_to_mha(predictions, os.path.join(segmentations, f\"{patient}_segmentation.mha\"), spacing, should_flip)\n",
    "   \n",
    "    print(f\"The process has been completed for the patient {patient}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer system details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-03-26T20:07:59.804054+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.4\n",
      "IPython version      : 8.15.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 126 Stepping 5, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
